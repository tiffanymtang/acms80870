{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelization Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from os.path import join as oj\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "import inspect\n",
    "\n",
    "sys.path.append('..') # add parent directory to path\n",
    "from python.fit import fit_rf_loo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper variables\n",
    "DATA_PATH = oj(\"..\", \"data\")\n",
    "n = 30  # Do leave-one-out for the first 30 samples for illustration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this parallelization example, we will be working with gene expression data from women with breast cancer from The Cancer Genome Atlas (TCGA). In particular, we will be using the gene expressions to predict their breast cancer subtype (Luminal A, Luminal B, Basal, Her2, Normal-like). Let's first load in this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(oj(DATA_PATH, \"X_tcga_cleaned.csv\")).values  # Convert to NumPy array\n",
    "y = pd.read_csv(oj(DATA_PATH, \"Y_tcga.csv\")).iloc[:, 0].values  # Convert to NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.61452694,  7.40176299, 10.85901081, ...,  0.        ,\n",
       "         6.60972707,  7.55111676],\n",
       "       [ 8.72532295,  9.37559946, 10.12843209, ...,  0.        ,\n",
       "         7.66576669,  7.31031678],\n",
       "       [ 8.67158522,  7.75682541, 10.69036948, ...,  0.30910104,\n",
       "         6.42531155,  7.9417606 ],\n",
       "       ...,\n",
       "       [ 9.36340306,  8.13355076, 10.27647796, ...,  0.        ,\n",
       "         6.9925986 ,  6.98624376],\n",
       "       [ 8.82015369,  5.66191514,  8.57902627, ...,  0.        ,\n",
       "         6.64379924,  7.58504255],\n",
       "       [ 9.81865415,  7.82862208,  9.9021779 , ...,  0.        ,\n",
       "         7.14774132,  7.28772567]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LumA', 'LumB', 'LumA', ..., 'LumA', 'LumA', 'LumA'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting leave-one-out models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of this demonstration, suppose that we want to evaluate the performance of a random forest model on this data using leave-one-out cross-validation (also known as the jackknife in statistics). To do so, there is a helper function `fit_rf_loo()` that takes in the covariate data `X`, the response variable `y`, and the index of the observation to leave out `i`. This function `fit_rf_loo()` fits a random forest model on the data with the `i`-th observation left out and returns the predicted class of the left-out `i`-th observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def fit_rf_loo(i, x, y, **kwargs):\n",
      "    # Remove the ith observation for leave-one-out\n",
      "    x_train = np.delete(x, i, axis=0)\n",
      "    y_train = np.delete(y, i)\n",
      "\n",
      "    # Train the RandomForestClassifier\n",
      "    rf = RandomForestClassifier(**kwargs)\n",
      "    rf.fit(x_train, y_train)\n",
      "\n",
      "    # Make a prediction on the left-out observation\n",
      "    preds = rf.predict(x[i:(i+1), :])[0]\n",
      "    return preds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(fit_rf_loo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Parallelization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first run the leave-one-out cross-validation without parallelization to see how long it takes. We will only run this on the first `n = 30` observations for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time without parallelization: 145.0246922969818\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "preds = np.empty(n, dtype=object)  # Vector of leave-one-out predictions\n",
    "for i in range(n):\n",
    "    preds[i] = fit_rf_loo(i, X, y)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(\"Execution time without parallelization:\", execution_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Parallelization using joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's run the leave-one-out cross-validation with parallelization using the `joblib` package. But before implementing this, let's check how many cores are available on this machine using `os.cpu_count()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to parallelize this code, there are two steps:\n",
    "\n",
    "**Step 1: Setting up the parallel backend.** This is done using `Parallel(n_jobs=...)`, where we specify the number of cores we would like to use.\n",
    "\n",
    "**Step 2: Re-write the code using futures (or `delayed()`)** Here, we need to put the code that we want to run in parallel into a single function (luckily, this is already done for us) and wrap that function call using `delayed()`. This essentially creates futures that can be evaluated in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time with joblib parallelization: 74.90133261680603\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "preds_parallel = Parallel(n_jobs=2)(delayed(fit_rf_loo)(i, X, y) for i in range(n))\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(\"Execution time with joblib parallelization:\", execution_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the predictions from the non-parallelized and parallelized implementations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preds</th>\n",
       "      <th>preds_parallel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LumA</td>\n",
       "      <td>LumA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LumA</td>\n",
       "      <td>LumA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LumA</td>\n",
       "      <td>LumA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LumB</td>\n",
       "      <td>LumB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Her2</td>\n",
       "      <td>Her2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  preds preds_parallel\n",
       "0  LumA           LumA\n",
       "1  LumA           LumA\n",
       "2  LumA           LumA\n",
       "3  LumB           LumB\n",
       "4  Her2           Her2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"preds\": preds, \"preds_parallel\": preds_parallel}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8333333333333334)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(preds == y[:n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Resources/Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- joblib: https://joblib.readthedocs.io/en/stable/ \n",
    "- multiprocessing: https://docs.python.org/3/library/multiprocessing.html \n",
    "- Dask: https://www.dask.org/ \n",
    "    - Great for handling large datasets and scaling operations from a single machine to a cluster\n",
    "- Ray: https://www.ray.io/ \n",
    "    - Useful for building distributed applications and handling complex parallel tasks across multiple machines\n",
    "- A great introductory tutorial covering joblib, multiprocessing, and Dask from Thomas Langford (Yale): https://docs.ycrc.yale.edu/parallel_python/#/ \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
